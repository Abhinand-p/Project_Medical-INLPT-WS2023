{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO NEED TO RUN THIS CELL AS THE DATA IS ALREADY COLLECTED AND SAVE UNDER articles.csv\n",
    "\n",
    "# Data Crawler that works exactly like a human and go one by one through the articles and save the abstracts and references in XML format\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Navigate to the website\n",
    "url = \"https://pubmed.ncbi.nlm.nih.gov/?term=intelligence+%5BTitle%2Fabstract%5D&filter=simsearch1.fha&filter=years.2013-2023&sort=date&size=200\"\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "driver.get(url)\n",
    "\n",
    "# Click the first article to start\n",
    "driver.find_element(By.XPATH, \"//a[@data-ga-action=1]\").click()\n",
    "total_articles = driver.find_element(By.XPATH, \"//*[@id='adjacent-navigation']/div[2]/a/span[1]/span[2]\").text\n",
    "\n",
    "# Find the number of total articles\n",
    "total_articles = re.sub(r\"[^3-9]\",'', total_articles)\n",
    "\n",
    "# Specify the chunk size\n",
    "chunk_size = 1000\n",
    "\n",
    "# Create empty lists to store data\n",
    "titles = []\n",
    "authors = []\n",
    "abstracts = []\n",
    "references_list = []\n",
    "not_found_pages = []\n",
    "\n",
    "for page in tqdm(range(int(total_articles))):\n",
    "    # Extract title of the article\n",
    "    try:\n",
    "        title = driver.find_element(By.CLASS_NAME, \"heading-title\")\n",
    "        if title.is_displayed():\n",
    "            title = title.text\n",
    "    except NoSuchElementException:\n",
    "        title = ''\n",
    "        pass\n",
    "\n",
    "    # Extract autors of the article\n",
    "    try:\n",
    "        authors_elements = driver.find_elements(By.CLASS_NAME, \"full-name\")\n",
    "        author_list = []\n",
    "        if len(authors_elements) > 0:\n",
    "            for author in authors_elements:\n",
    "                author_list.append(author.text)\n",
    "    except NoSuchElementException:\n",
    "        author_list.append('')\n",
    "        pass\n",
    "\n",
    "    # Extract abstract of the article\n",
    "    try:\n",
    "        abstract = driver.find_element(By.ID, \"eng-abstract\")\n",
    "        if abstract.is_displayed():\n",
    "            abstract = abstract.text\n",
    "    except NoSuchElementException:\n",
    "        abstract = ''\n",
    "        pass\n",
    "\n",
    "    # Check and extract if there is reference or are more references \n",
    "    try:\n",
    "        reference = driver.find_element(By.ID, \"references\")\n",
    "        show_all_element = driver.find_element(By.CLASS_NAME, \"show-all\")\n",
    "        if show_all_element.is_displayed():\n",
    "            show_all_element.click()\n",
    "        if reference.is_displayed():\n",
    "            references = driver.find_element(By.CLASS_NAME, \"references-list\").text\n",
    "    except NoSuchElementException:\n",
    "        references = ''\n",
    "        pass\n",
    "\n",
    "    # Append data to lists\n",
    "    titles.append(title)\n",
    "    authors.append(author_list)\n",
    "    abstracts.append(abstract)\n",
    "    references_list.append(references)\n",
    "\n",
    "    if (page + 1) % chunk_size == 0 or page + 1 == int(total_articles):\n",
    "        # Create a DataFrame\n",
    "        data = {\n",
    "                    'Title': pd.Series(titles),\n",
    "                    'Authors': pd.Series(authors),\n",
    "                    'Abstracts': pd.Series(abstracts),\n",
    "                    'References': pd.Series(references_list)\n",
    "                }\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Save DataFrame to CSV\n",
    "        chunk_number = (page + 1) // chunk_size\n",
    "        csv_filename = f'pubmed_data_chunk_{chunk_number}.csv'\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "\n",
    "        # Clear lists for the next chunk\n",
    "        titles = []\n",
    "        authors = []\n",
    "        abstracts = []\n",
    "        references_list = []\n",
    "    \n",
    "    # Navigate to the next article\n",
    "    try:\n",
    "        next_page = driver.find_element(By.XPATH, \"//div[@class='next side-link visible']\")\n",
    "        if next_page.is_displayed():\n",
    "            next_page.click()\n",
    "    except NoSuchElementException:\n",
    "        not_found_pages.append(page)\n",
    "        print(f\"{page = } not found!\")\n",
    "        pass\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

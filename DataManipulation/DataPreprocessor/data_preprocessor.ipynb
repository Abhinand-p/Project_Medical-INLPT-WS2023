{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing to have a CSV file with the following columns and respective data in each row:\n",
    "# which will be filtered later to have just useful columns and non dupplicated PMID\n",
    "\n",
    "\"\"\"\n",
    "df shape before cleaning:(74243, 77)\n",
    "df shape after cleaning:(57560, 15)\n",
    "\n",
    "Index(['PMID', 'STAT', 'DRDT', 'CTDT', 'PB', 'DP', 'TI', 'BTI', 'AB', 'CI',\n",
    "       'FED', 'ED', 'FAU', 'AU', 'AD', 'LA', 'PT', 'PL', 'OTO', 'OT', 'EDAT',\n",
    "       'CRDT', 'AID', 'OWN', 'DCOM', 'LR', 'IS', 'VI', 'IP', 'PG', 'LID',\n",
    "       'DEP', 'TA', 'JT', 'JID', 'SB', 'MH', 'MHDA', 'PHST', 'PST', 'SO', 'GR',\n",
    "       'PMC', 'MID', 'COIS', 'TT', 'RN', 'OID', 'SI', 'ISBN', 'CTI', 'CN',\n",
    "       'FIR', 'IR', 'AUID', 'EIN', 'CIN', 'PS', 'FPS', 'CON', 'UOF', 'UIN',\n",
    "       'RIN', 'IRAD', 'EFR', 'OAB', 'OABL', 'PMCR', 'CP', 'ECI', 'DRIN', 'RF',\n",
    "       'EN', 'ROF', 'RPI', 'RPF', 'DDIN'],\n",
    "      dtype='object')\n",
    "\n",
    "\n",
    "Guide to the abbreviations:\n",
    "\n",
    "    PMID: PubMed IDentifier - Unique identifier for a PubMed record.\n",
    "\n",
    "    TI: Title - The title of the article.\n",
    "\n",
    "    AB: Abstract - A brief summary of the article's content.\n",
    "\n",
    "    PB: Publisher - The organization responsible for publishing the article.\n",
    "\n",
    "    FAU: Full Author(s) - Full names of the authors.\n",
    "\n",
    "    FED: Full Editor(s) - Full names of the editors.\n",
    "\n",
    "    DP: Date of Publication - Date when the article was published.\n",
    "\n",
    "    OTO: Other Term Owner - Owner of other terms.\n",
    "\n",
    "    OT: Other Term - Additional terms or keywords associated with the article.\n",
    "\n",
    "    OWN: Owner - Owner of the article.\n",
    "\n",
    "    DCOM: Date Completed - Date when the article was completed.\n",
    "\n",
    "    LR: Last Revision - Last revision date.\n",
    "\n",
    "    JT: Journal Title - Full title of the journal.\n",
    "\n",
    "    MH: MeSH Terms - Medical Subject Headings.\n",
    "\n",
    "    ISBN: International Standard Book Number - ISBN of the article.\n",
    "\n",
    "[Removed]    STAT: Status - Indicates the status of the publication.\n",
    "\n",
    "[Removed]    DRDT: Date Received by Database Transfer - Date when the record was received by the database.\n",
    "\n",
    "[Removed]    CTDT: Current Temporary Date - Current temporary date of the record.\n",
    "\n",
    "[Removed]    BTI: Book Title Indicator - Indicates that the article is part of a book.\n",
    "\n",
    "[Removed]    CI: Copyright Information - Information about the copyright holder.\n",
    "\n",
    "[Removed]    ED: Editor - Abbreviation for the editor.\n",
    "\n",
    "[Removed]    AU: Author - Abbreviation for the author.\n",
    "\n",
    "[Removed]    AD: Author's Affiliation - Affiliation or institution of the author.\n",
    "\n",
    "[Removed]    LA: Language - Language of the article.\n",
    "\n",
    "[Removed]    PT: Publication Type - Type of publication (e.g., Review, Book Chapter).\n",
    "\n",
    "[Removed]    PL: Place of Publication - Location where the article was published.\n",
    "\n",
    "[Removed]    EDAT: Entrez Date - Date the record was added to the Entrez database.\n",
    "\n",
    "[Removed]    CRDT: Create Date - Date the record was created.\n",
    "\n",
    "[Removed]    AID: Article Identifier - Identifier associated with the article.\n",
    "\n",
    "[Removed]    IS: Issue - Issue number of the journal.\n",
    "\n",
    "[Removed]    VI: Volume - Volume number of the journal.\n",
    "\n",
    "[Removed]    IP: Issue Part - Part number of the issue.\n",
    "\n",
    "[Removed]    PG: Page - Page number.\n",
    "\n",
    "[Removed]    LID: Location IDentifier - Identifier for the location of the article.\n",
    "\n",
    "[Removed]    DEP: Date of Electronic Publication - Date of electronic publication.\n",
    "\n",
    "[Removed]    TA: Journal Title (ISO abbreviation) - Title abbreviation of the journal.\n",
    "\n",
    "[Removed]    JID: Journal ID - Identifier for the journal.\n",
    "\n",
    "[Removed]    SB: Subset - Subset designation.\n",
    "\n",
    "[Removed]    MHDA: MeSH Date - MeSH date.\n",
    "\n",
    "[Removed]    PHST: Publication History Status - Publication history status.\n",
    "\n",
    "[Removed]    PST: Publication Status - Publication status.\n",
    "\n",
    "[Removed]    SO: Source - Source of the article.\n",
    "\n",
    "[Removed]    GR: Grant - Grant information.\n",
    "\n",
    "[Removed]    PMC: PubMed Central ID - Identifier for PubMed Central.\n",
    "\n",
    "[Removed]    MID: Manuscript ID - Identifier for the manuscript.\n",
    "\n",
    "[Removed]    COIS: Conflict of Interest Statement - Statement about potential conflicts of interest.\n",
    "\n",
    "[Removed]    TT: Type of Test - Type of test.\n",
    "\n",
    "[Removed]    RN: Registry Number - Registry number.\n",
    "\n",
    "[Removed]    OID: Organization ID - Identifier for the organization.\n",
    "\n",
    "[Removed]    SI: Secondary Source ID - Secondary source identifier.\n",
    "\n",
    "[Removed]    CTI: Current Technology Information - Current technology information.\n",
    "\n",
    "[Removed]    CN: Contract Number - Contract number.\n",
    "\n",
    "[Removed]    FIR: Full Investigator(s) - Full names of the investigators.\n",
    "\n",
    "[Removed]    IR: Investigator - Abbreviation for the investigator.\n",
    "\n",
    "[Removed]    AUID: Author ID - Identifier for the author.\n",
    "\n",
    "[Removed]    EIN: Editor's ID - Identifier for the editor.\n",
    "\n",
    "[Removed]    CIN: Contributor ID - Identifier for the contributor.\n",
    "\n",
    "[Removed]    PS: Personal Name as Subject - Personal name as subject.\n",
    "\n",
    "[Removed]    FPS: Full Personal Name as Subject - Full personal name as subject.\n",
    "\n",
    "[Removed]    CON: Consortium - Consortium information.\n",
    "\n",
    "[Removed]    UOF: Use of Funds - Use of funds information.\n",
    "\n",
    "[Removed]    UIN: Unique Identifier - Unique identifier.\n",
    "\n",
    "[Removed]    RIN: Reviewer ID - Reviewer identifier.\n",
    "\n",
    "[Removed]    IRAD: Investigator Affiliation Department - Investigator affiliation department.\n",
    "\n",
    "[Removed]    EFR: EFS (Endoscopic Frequency Standardization) Factor - EFS factor.\n",
    "\n",
    "[Removed]    OAB: Overall Bank - Overall bank.\n",
    "\n",
    "[Removed]    OABL: Overall Blood - Overall blood.\n",
    "\n",
    "[Removed]    PMCR: PubMed Central Release - PubMed Central release information.\n",
    "\n",
    "[Removed]    CP: Clinical Progress - Clinical progress.\n",
    "\n",
    "[Removed]    ECI: Early Career Investigator - Early career investigator.\n",
    "\n",
    "[Removed]    DRIN: Dual Purpose Experimental Purpose Indicator - Dual-purpose experimental purpose indicator.\n",
    "\n",
    "[Removed]    RF: Release Factor - Release factor.\n",
    "\n",
    "[Removed]    EN: Endorsement - Endorsement.\n",
    "\n",
    "[Removed]    ROF: Reviewer's Office - Reviewer's office.\n",
    "\n",
    "[Removed]    RPI: Reviewer's Position Identifier - Reviewer's position identifier.\n",
    "\n",
    "[Removed]    RPF: Research Performance Factor - Research performance factor.\n",
    "\n",
    "[Removed]    DDIN: Degree-Degree Integration Network - Degree-degree integration network.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "with open('../data_pool/articles.txt', 'r', encoding='utf-8') as f:\n",
    "    input_text = f.read()\n",
    "\n",
    "# Split articles based on double quotes\n",
    "articles = re.split(r'\\n\"\\n', input_text.strip())\n",
    "\n",
    "# Define a function to extract data from each article\n",
    "def extract_data(article):\n",
    "    data = {}\n",
    "    current_key = None\n",
    "    current_value = ''\n",
    "\n",
    "    for line in article.split('\\n'):\n",
    "        # matching the key-value pair\n",
    "        match = re.match(r'^([A-Z]{2,4})\\s*- (.+)$', line)\n",
    "\n",
    "        if match:\n",
    "            key, value = match.groups()\n",
    "            if current_key:\n",
    "                # If a key is already set, save the current value\n",
    "                if current_key in data:\n",
    "                    data[current_key] += '|' + current_value\n",
    "                else:\n",
    "                    data[current_key] =  current_value.strip()\n",
    "                current_value = ''  # Reset current value\n",
    "\n",
    "            current_key = key\n",
    "            current_value = value\n",
    "        else:\n",
    "            # If there's no match, append the line to the current value\n",
    "            current_value += '' + line.strip()\n",
    "\n",
    "    # Save the last key-value pair\n",
    "    if current_key:\n",
    "        data[current_key] = current_value.strip()\n",
    "\n",
    "    return data\n",
    "\n",
    "# Extract data from each article\n",
    "article_data_list = [extract_data(article) for article in articles]\n",
    "\n",
    "# Filter out articles without 'AB' key\n",
    "filtered_data_list = [data for data in article_data_list if 'AB' in data]\n",
    "\n",
    "# Create a DataFrame from the filtered data\n",
    "df = pd.DataFrame(filtered_data_list)\n",
    "\n",
    "# Keep only useful columns:  df shape before cleaning:(74243, 77)\n",
    "df = df[['PMID', 'TI', 'AB', 'PB', 'FAU', 'FED', 'DP', 'OTO', 'OT', 'OWN', 'DCOM', 'LR', 'JT', 'MH', 'ISBN']]\n",
    "\n",
    "# Drop duplicates based on the 'PMID' column : df shape after cleaning:(57560, 15)\n",
    "df = df.drop_duplicates(subset='PMID', keep='first')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('../data_pool/articles.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conbine different columns of the dataset into one column\n",
    "import pandas as pd\n",
    "\n",
    "# Read the original CSV file\n",
    "df_part = pd.read_csv('articles.csv', index_col='PMID', usecols=['PMID', 'TI', 'AB', 'FAU', 'DP', 'OT', 'JT', 'MH'])\n",
    "\n",
    "# Create a new DataFrame with the desired structure\n",
    "new_df = pd.DataFrame(index=df_part.index)\n",
    "\n",
    "# Combine the information into a single column\n",
    "new_df['Combined_Info'] = (\n",
    "    'Title: ' + df_part['TI'].fillna('None') + '\\n' +\n",
    "    'Abstract: ' + df_part['AB'].fillna('None') + '\\n' +\n",
    "    'Authors: ' + df_part['FAU'].fillna('None') + '\\n' +\n",
    "    'Data of Publication: ' + df_part['DP'].fillna('None') + '\\n' +\n",
    "    'Terms or keywords associated with the article: ' + df_part['OT'].fillna('None') + '\\n' +\n",
    "    'Journal Title: ' + df_part['JT'].fillna('None') + '\\n' +\n",
    "    'Medical subject headings: ' + df_part['MH'].fillna('None')\n",
    ")\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "new_df.to_csv('combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the large CSV file into smaller chunks\n",
    "import pandas as pd\n",
    "\n",
    "def split_csv(input_csv, output_prefix, chunk_size):\n",
    "    # Read the large CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Determine the number of chunks needed\n",
    "    num_chunks = (len(df) // chunk_size) + 1\n",
    "\n",
    "    # Split the DataFrame into chunks\n",
    "    chunks = [df[i * chunk_size:(i + 1) * chunk_size] for i in range(num_chunks)]\n",
    "\n",
    "    # Save each chunk as a separate CSV file\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        output_csv = f\"{output_prefix}_{i + 1}.csv\"\n",
    "        chunk.to_csv(output_csv, index=False)\n",
    "        print(f\"Chunk {i + 1} saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "input_csv_path = 'data_1.csv'  # Replace with the path to your large CSV file\n",
    "output_prefix = 'sub_data'  # Prefix for the output CSV files\n",
    "chunk_size = 1000  # Number of rows per chunk\n",
    "\n",
    "split_csv(input_csv_path, output_prefix, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new CSV file with the filtered 'CD' column that contains useful information\n",
    "# and is the main dataset to be used for the project\n",
    "import pandas as pd\n",
    "\n",
    "# Read the original CSV file\n",
    "df_part = pd.read_csv('articles.csv', index_col='PMID', usecols=['PMID', 'TI', 'AB', 'FAU', 'DP', 'OT', 'JT', 'MH'])\n",
    "\n",
    "# Create a new DataFrame with the desired structure\n",
    "new_df = pd.DataFrame(index=df_part.index)\n",
    "\n",
    "# Combine the information into a single column\n",
    "new_df['CD'] = (\n",
    "    'PMID: ' + df_part.index.astype(str) + '\\n' +\n",
    "    'Abstract: ' + df_part['AB'].fillna('None') + '\\n' +\n",
    "    'Title: ' + df_part['TI'].fillna('None') + '\\n' +\n",
    "    'Authors: ' + df_part['FAU'].fillna('None') + ',\\n' +\n",
    "    'Data of Publication: ' + df_part['DP'].fillna('None') + '\\n' +\n",
    "    'Terms or keywords associated with the article: ' + df_part['OT'].fillna('None') + '\\n' +\n",
    "    'Journal Title: ' + df_part['JT'].fillna('None') + '\\n' +\n",
    "    'Medical subject headings: ' + df_part['MH'].fillna('None') + '\\n'# +\n",
    "    # 'Abstract: ' + df_part['AB'].fillna('None')\n",
    ")\n",
    "new_df['source'] = 'https://pubmed.ncbi.nlm.nih.gov/' + df_part.index.astype(str)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# # Read your DataFrame from a CSV file\n",
    "# df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Function to filter out lines ending with 'None' from a given text\n",
    "def filter_lines(text):\n",
    "    lines = text.split('\\n')\n",
    "    filtered_lines = [line for line in lines if not line.strip().endswith('None')]\n",
    "    return ', '.join(filtered_lines)\n",
    "\n",
    "# Apply the filtering function to each row in the 'CD' column\n",
    "new_df['CD'] = new_df['CD'].apply(filter_lines)\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "new_df.to_csv('additional_data.csv')\n",
    "# Print the DataFrame with the filtered 'CD' column\n",
    "new_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

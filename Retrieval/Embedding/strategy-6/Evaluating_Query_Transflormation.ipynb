{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import os\n",
        "import numpy as np\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.util import ngrams\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "metadata": {
        "id": "gwbDKnQq-kIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "F4ia8fNg-l9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the approaches to Task Decomposition?\"\n",
        "\n",
        "transformed_queries = [\n",
        "    \"How can Task Decomposition be approached?\",\n",
        "    \"What are the different methods for Task Decomposition?\",\n",
        "    \"What are the various approaches to decomposing tasks?\"\n",
        "]"
      ],
      "metadata": {
        "id": "zdaTtTE3-mGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_similarity_scores(query, transformed_queries):\n",
        "    query_similarity_scores = []\n",
        "    word_overlap_scores = []\n",
        "    bleu_scores = []\n",
        "\n",
        "    for transformed_query in transformed_queries:\n",
        "        # Similarity score\n",
        "        similarity_score = len(set(query.lower().split()).intersection(set(transformed_query.lower().split()))) / len(set(query.lower().split()).union(set(transformed_query.lower().split())))\n",
        "        query_similarity_scores.append(similarity_score)\n",
        "\n",
        "        # Word overlap\n",
        "        # Calculate the percentage of overlapping words between the original query and its transformed version.\n",
        "        query_words = set(query.lower().split())\n",
        "        transformed_query_words = set(transformed_query.lower().split())\n",
        "        overlap_score = len(query_words.intersection(transformed_query_words)) / len(query_words.union(transformed_query_words))\n",
        "        word_overlap_scores.append(overlap_score)\n",
        "\n",
        "        # BLEU score\n",
        "        bleu_score = sentence_bleu([query.lower().split()], transformed_query.lower().split())\n",
        "        bleu_scores.append(bleu_score)\n",
        "\n",
        "    return query_similarity_scores, word_overlap_scores, bleu_scores"
      ],
      "metadata": {
        "id": "AvnQRTO2Aj4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_similarity_scores, word_overlap_scores, bleu_scores = calculate_similarity_scores(query, transformed_queries)\n",
        "\n",
        "print(\"Query Similarity Scores:\", query_similarity_scores)\n",
        "print(\"Word Overlap Scores:\", word_overlap_scores)\n",
        "print(\"BLEU Scores:\", bleu_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHfRx_nUAoPj",
        "outputId": "1554090f-6ca7-44c2-c9b6-53b49ad5266d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Similarity Scores: [0.08333333333333333, 0.5, 0.5]\n",
            "Word Overlap Scores: [0.08333333333333333, 0.5, 0.5]\n",
            "BLEU Scores: [9.853445011990208e-232, 5.614021910443866e-78, 5.614021910443866e-78]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semantic Similarity:\n",
        "Utilising pre-trained word embeddings(GloVe) to compute the semantic similarity between the original query and its transformed version to capture the similarity in meaning between the queries."
      ],
      "metadata": {
        "id": "VyYu5011HgZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_model(glove_file):\n",
        "    print(\"Loading GloVe Model\")\n",
        "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "        word_to_vec = {}\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vec = np.array(values[1:], dtype='float32')\n",
        "            word_to_vec[word] = vec\n",
        "    print(\"Done.\", len(word_to_vec), \" words loaded!\")\n",
        "    return word_to_vec\n",
        "\n",
        "def compute_semantic_similarity(query, transformed_query, word_to_vec):\n",
        "    query_embedding = np.mean([word_to_vec[word] for word in query.lower().split() if word in word_to_vec], axis=0)\n",
        "    transformed_query_embedding = np.mean([word_to_vec[word] for word in transformed_query.lower().split() if word in word_to_vec], axis=0)\n",
        "\n",
        "    if np.all(np.isnan(query_embedding)) or np.all(np.isnan(transformed_query_embedding)):\n",
        "        return 0.0\n",
        "\n",
        "    similarity_score = np.dot(query_embedding, transformed_query_embedding) / (np.linalg.norm(query_embedding) * np.linalg.norm(transformed_query_embedding))\n",
        "    return similarity_score"
      ],
      "metadata": {
        "id": "x8P88RqvDkp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_txt_path = \"glove.6B.50d.txt\"\n",
        "word_to_vec = load_glove_model(glove_txt_path)\n",
        "\n",
        "semantic_similarity_scores = []\n",
        "for transformed_query in transformed_queries:\n",
        "    semantic_similarity_score = compute_semantic_similarity(query, transformed_query, word_to_vec)\n",
        "    semantic_similarity_scores.append(semantic_similarity_score)\n",
        "\n",
        "for i, transformed_query in enumerate(transformed_queries):\n",
        "    print(\"Semantic Similarity Score for transformed query\", i+1, \":\", semantic_similarity_scores[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qaBWBfmE8QZ",
        "outputId": "c26cc98b-9f94-427a-a9ae-953c890fe8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading GloVe Model\n",
            "Done. 400000  words loaded!\n",
            "Semantic Similarity Score for transformed query 1 : 0.9197151\n",
            "Semantic Similarity Score for transformed query 2 : 0.97984254\n",
            "Semantic Similarity Score for transformed query 3 : 0.9665459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semantic Similarity utilizing custom embeddings:\n",
        "Utilising custom word embeddings to compute the semantic similarity between the original query and its transformed version to capture the similarity in meaning between the queries.\n",
        "\n",
        "// #TODO: integrate this with previously utilised embeddings."
      ],
      "metadata": {
        "id": "Qkxp1ETnHn1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LangChain\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "custom_embeddings_file = \"custom/embeddings.txt\"\n",
        "# word_to_vec_custom = langchain.encode(texts)\n",
        "\n",
        "semantic_similarity_scores_custom = []\n",
        "for transformed_query in transformed_queries:\n",
        "    semantic_similarity_score = compute_semantic_similarity(query, transformed_query, word_to_vec)\n",
        "    semantic_similarity_scores_custom.append(semantic_similarity_score)\n",
        "\n",
        "for i, transformed_query in enumerate(transformed_queries):\n",
        "    print(\"Semantic Similarity Score for transformed query utilizing custom embeddings\", i+1, \":\", semantic_similarity_scores_custom[i])"
      ],
      "metadata": {
        "id": "v0DFSDbvG6t2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
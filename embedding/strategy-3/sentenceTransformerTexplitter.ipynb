{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f20263e-8813-4a89-a1a2-bf6e4b4b5bfc",
   "metadata": {},
   "source": [
    "<h1>Installs</h1>\n",
    "- This file prepares the data such that we can upload it to opensearch (So that we can have vecotrs and metadata all in one DB). We use the same e5 model as in strategy_1 but chunk the data with the SentenceTransformersTokenTextSplitter method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6abada0f-1fcb-4f45-a041-42e87d3f0f69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pinecone-client in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (2.2.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from pinecone-client) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from pinecone-client) (6.0.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from pinecone-client) (0.7.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from pinecone-client) (4.8.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from pinecone-client) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from pinecone-client) (2.0.6)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from pinecone-client) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from pinecone-client) (1.26.0)\n",
      "Requirement already satisfied: six>=1.5 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests>=2.19.0->pinecone-client) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests>=2.19.0->pinecone-client) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faunadb in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (4.5.1)\n",
      "Requirement already satisfied: iso8601 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from faunadb) (2.1.0)\n",
      "Requirement already satisfied: requests in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from faunadb) (2.31.0)\n",
      "Requirement already satisfied: future in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from faunadb) (0.18.3)\n",
      "Requirement already satisfied: httpx[http2] in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from faunadb) (0.25.2)\n",
      "Requirement already satisfied: anyio in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from httpx[http2]->faunadb) (4.0.0)\n",
      "Requirement already satisfied: certifi in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from httpx[http2]->faunadb) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from httpx[http2]->faunadb) (1.0.2)\n",
      "Requirement already satisfied: idna in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from httpx[http2]->faunadb) (3.4)\n",
      "Requirement already satisfied: sniffio in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from httpx[http2]->faunadb) (1.3.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from httpx[http2]->faunadb) (4.1.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from httpcore==1.*->httpx[http2]->faunadb) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests->faunadb) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests->faunadb) (2.0.6)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]->faunadb) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]->faunadb) (4.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from anyio->httpx[http2]->faunadb) (1.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ndg-httpsclient in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (0.5.1)\n",
      "Requirement already satisfied: PyOpenSSL in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from ndg-httpsclient) (23.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from ndg-httpsclient) (0.5.0)\n",
      "Requirement already satisfied: cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from PyOpenSSL->ndg-httpsclient) (41.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->PyOpenSSL->ndg-httpsclient) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from cffi>=1.12->cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->PyOpenSSL->ndg-httpsclient) (2.21)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyopenssl in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (23.2.0)\n",
      "Requirement already satisfied: cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from pyopenssl) (41.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyopenssl) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from cffi>=1.12->cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyopenssl) (2.21)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyasn1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (0.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from sentence-transformers) (4.36.1)\n",
      "Requirement already satisfied: tqdm in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: torchvision in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from sentence-transformers) (0.16.2)\n",
      "Requirement already satisfied: numpy in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from sentence-transformers) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from sentence-transformers) (1.11.3)\n",
      "Requirement already satisfied: nltk in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from sentence-transformers) (0.19.4)\n",
      "Requirement already satisfied: filelock in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.9.2)\n",
      "Requirement already satisfied: requests in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: click in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from torchvision->sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (4.36.1)\n",
      "Requirement already satisfied: filelock in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /pfs/data5/home/hd/hd_hd/hd_hi268/.local/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /pfs/data5/software_uc2/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pinecone-client\n",
    "! pip install faunadb\n",
    "! pip install ndg-httpsclient\n",
    "! pip install pyopenssl\n",
    "! pip install pyasn1\n",
    "! pip install -U sentence-transformers\n",
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7c76d1-be5b-494b-8091-c5007faf2ea4",
   "metadata": {},
   "source": [
    "\n",
    "<h1>Extract Data from .csv</h1>\n",
    "*   AB = Column that corresponds to the text of the abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d510cc2f-78b5-4f07-aeea-d4d852f61c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from itertools import islice\n",
    "import uuid\n",
    "\n",
    "# Load data, store abstract text\n",
    "batch_input = []\n",
    "with open('../data/INLPT_class/articles.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        batch_input.append([row[\"AB\"],row[\"PMID\"],row[\"TI\"],row[\"PB\"],row[\"FAU\"],row[\"FED\"],row[\"DP\"],row[\"OTO\"], row[\"OT\"],row[\"OWN\"], row[\"LR\"], row[\"JT\"], row[\"MH\"],row[\"ISBN\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2dcb141-3b5e-49d2-bb8d-55a065104196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57560\n"
     ]
    }
   ],
   "source": [
    "print(len(batch_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf2a0c-3517-46b2-848f-4d5ccef9055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "<h1>Embedd Data from .csv</h1>\n",
    "1. DIvide each abstract into chunks such that each chunks text will be tokenized to max 512 Tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "988a2a59-fa72-4a27-93d9-3ef89f6b92a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a335999a3142189a0ccbab4ac89947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9578d355fc95438cb7f7e74994a21fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f48b82d50b4ae1991467b9a83475fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/67.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b46d599e873445fa30e5314c569b212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c495014ceb854d798d3491ad23adbc84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0433d2677d4342e5a460b79bccf5363d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfc323c106e40c48d44861cd52de6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.onnx:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ee43ac116f4edcaf892a26895ed311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb462c99ee84e5bac214c26232db873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5f3027c7af474b8d22ce43ee9c06a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c60cad7c37d48f796dd66bae7589576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774eb0efd84046dfa5c446fa60c1469d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ea73a9c24b425583738a3f9275a24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c237794d974e189f1b7f212dddcf8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6dfe4d3822148e18032d220b2840007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0600d28dca4f858aaa88df7b58f142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800a9b4e0bc445598cab7cfe8123bae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16ceb385852415282ad6c631f1da2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea3f1e2f9fa45bb8fcd672b913dfdc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad847da1c7841e499b0edb76bef05a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a25e7dd91a4ebea42e8b8bf73cd28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2ec72e1ed742fb8ea0fc706dad2a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      "  (2): Normalize()\n",
      ")\n",
      "BertTokenizerFast(name_or_path='intfloat/e5-base-v2', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "import re\n",
    "import tqdm\n",
    "\n",
    "#embed data\n",
    "# model = SentenceTransformer('pritamdeka/S-PubMedBert-MS-MARCO')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('pritamdeka/S-PubMedBert-MS-MARCO')\n",
    "# max_token_size = 350\n",
    "# print(model)\n",
    "# print(tokenizer)\n",
    "\n",
    "model_name = 'intfloat/e5-base-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "max_token_size = 512\n",
    "print(model)\n",
    "print(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb97f0fe-f082-49b0-8eca-1194fba8d01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "splitter = SentenceTransformersTokenTextSplitter(\n",
    "    model_name=model_name,  \n",
    "    chunk_overlap=20,  \n",
    ")\n",
    "print(splitter.maximum_tokens_per_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30639f20-b9eb-440a-a81e-9e169dc5f52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 01:09:28.944477: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-12 01:09:30.184028: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-12 01:09:30.184064: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-12 01:09:30.184094: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-12 01:09:30.722738: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-12 01:09:52.505984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "chunked_data = []\n",
    "\n",
    "#Chunk abstract text, prepare for emebdding\n",
    "for abstract_text in batch_input:\n",
    "    chunked_data.append(splitter.split_text(text=abstract_text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f78af6bb-c891-4ed2-af47-31115b22a025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57560\n"
     ]
    }
   ],
   "source": [
    "print(len(chunked_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b9ac7db-072e-475c-b86e-da7c4560c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "\n",
    "#flatten data and append metadata to each chunk -> list of [chunk, PMID, TI, PB, FAU, FED,DP,OTO,ISBN]\n",
    "for id, abstract in enumerate(chunked_data):\n",
    "    for chunk in abstract:\n",
    "        chunks.append([chunk, batch_input[id][1],batch_input[id][2],batch_input[id][3],batch_input[id][4],batch_input[id][5],batch_input[id][6],batch_input[id][7],batch_input[id][8],batch_input[id][9],batch_input[id][10],batch_input[id][11],batch_input[id][12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c861d53-2b47-4424-a5ba-c808ce588247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63398\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "596f336e-7584-4bd7-bd65-6008ad59c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc13bf1-384f-4fa5-b600-71dfc17b1f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 50546/63398 [09:46<02:30, 85.37it/s]"
     ]
    }
   ],
   "source": [
    "#add embedding vector of chunk to the list\n",
    "for chunk in tqdm(chunks):\n",
    "    chunk.insert(0, model.encode(chunk[0]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198a944-f850-4880-b83e-b16971544633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#save List in File. This file will be later accesssed and the data will be uploaded to open search\n",
    "\n",
    "path = \"./data/data.txt\"\n",
    "with open(path, 'wb') as file:\n",
    "    pickle.dump(chunks, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426dfab-5494-4fc0-aa90-da5512fd14e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uujCycZ265g6"
      },
      "outputs": [],
      "source": [
        "! pip install -U sentence-transformers\n",
        "! pip install pinecone-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKs6pKMBBwWK"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from itertools import islice\n",
        "\n",
        "#Load data\n",
        "batch_input = []\n",
        "with open('/content/drive/MyDrive/data/INLPT_data/articles.csv') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    for row in reader:\n",
        "        batch_input.append((row[\"PMID\"],row[\"TI\"],row[\"AB\"],row[\"PB\"],row[\"FAU\"],row[\"FED\"],row[\"DP\"],row[\"OTO\"],row[\"OT\"],row[\"OWN\"],row[\"DCOM\"],row[\"LR\"],row[\"JT\"],row[\"MH\"],row[\"ISBN\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn_vZZmE-Fi7"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "#Embed Abstract text which is AB column\n",
        "model = SentenceTransformer('pritamdeka/S-PubMedBert-MS-MARCO')\n",
        "embeddings = [model.encode(chunk[2]) for chunk in batch_input]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g5muWkFAw4r"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "vectors = []\n",
        "\n",
        "createvec = [{vectors.append((\n",
        "    str(uuid.uuid1()),\n",
        "    embeddings[i].tolist(),\n",
        "    {\"PMID\": data[0], \"TI\": data[1],\"AB\": data[2], \"PB\": data[3], \"FAU\": data[4],\"FED\": data[5],\"DP\": data[6],\"OTO\": data[7],\"OT\": data[8],\"OWN\": data[9],\"DCOM\": data[10],\"LR\": data[11],\"JT\": data[12],\"MH\": data[13],\"ISBN\": data[14]}\n",
        "))} for i, data in enumerate(batch_input)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOS8BZSwAk8T"
      },
      "outputs": [],
      "source": [
        "import pinecone\n",
        "\n",
        "#Init pinecone index\n",
        "pinecone.init(api_key=\"4d2c2cd0-cf55-43c5-afb1-11001dc68709\", environment=\"gcp-starter\")\n",
        "index = pinecone.Index(\"inlp-ws2324-med\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Problem: storing abstract as metadata doesn't work: metadata size limit is 40kB, ours partially exceed by up to 60 kB \\n\n",
        "\n",
        "Solutions:\n",
        "- Upload embeddings + id into Pinecone, Upload text, metadata etc. into 2. Database (f.e. MongoDB). Once data is retrieved from pinecone via similarity search query text via id from 2. DB\n",
        "- Split up abstracts \n",
        "- use different cloud based vector db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhdCEoonU1UJ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import itertools\n",
        "\n",
        "def chunks(iterable, batch_size=100):\n",
        "    \"\"\"A helper function to break an iterable into chunks of size batch_size.\"\"\"\n",
        "    it = iter(iterable)\n",
        "    chunk = tuple(itertools.islice(it, batch_size))\n",
        "    while chunk:\n",
        "        yield chunk\n",
        "        chunk = tuple(itertools.islice(it, batch_size))\n",
        "\n",
        "vector_dim = 768\n",
        "\n",
        "# Upsert data with 100 vectors per upsert request\n",
        "for ids_vectors_chunk in chunks(vectors, batch_size=100):\n",
        "    index.upsert(vectors=ids_vectors_chunk)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

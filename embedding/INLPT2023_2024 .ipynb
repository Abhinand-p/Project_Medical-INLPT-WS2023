{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Installs</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook has the code for preparing, embedding and uploading the abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uujCycZ265g6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-2.2.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting requests>=2.19.0 (from pinecone-client)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pyyaml>=5.4 (from pinecone-client)\n",
      "  Using cached PyYAML-6.0.1-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting loguru>=0.5.0 (from pinecone-client)\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting typing-extensions>=3.7.4 (from pinecone-client)\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\john\\appdata\\roaming\\python\\python312\\site-packages (from pinecone-client) (2.8.2)\n",
      "Collecting urllib3>=1.21.1 (from pinecone-client)\n",
      "  Using cached urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting tqdm>=4.64.1 (from pinecone-client)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.22.0 (from pinecone-client)\n",
      "  Downloading numpy-1.26.3-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.2/61.2 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\john\\appdata\\roaming\\python\\python312\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.6)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru>=0.5.0->pinecone-client)\n",
      "  Downloading win32_setctime-1.1.0-py3-none-any.whl (3.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\john\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.19.0->pinecone-client)\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.19.0->pinecone-client)\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.19.0->pinecone-client)\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading pinecone_client-2.2.4-py3-none-any.whl (179 kB)\n",
      "   ---------------------------------------- 0.0/179.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 179.4/179.4 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "   ---------------------------------------- 0.0/300.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 300.4/300.4 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.5/62.5 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.3-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.6/15.5 MB 18.2 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.2/15.5 MB 15.4 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.7/15.5 MB 15.2 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.7/15.5 MB 15.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.4/15.5 MB 10.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.4/15.5 MB 10.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.4/15.5 MB 11.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.4/15.5 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.2/15.5 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.8/15.5 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.4/15.5 MB 13.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 7.0/15.5 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.6/15.5 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.2/15.5 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.6/15.5 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.4/15.5 MB 13.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.1/15.5 MB 13.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.8/15.5 MB 13.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.4/15.5 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.0/15.5 MB 14.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.6/15.5 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.2/15.5 MB 14.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.5 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.5/15.5 MB 14.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.1/15.5 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 12.6 MB/s eta 0:00:00\n",
      "Using cached PyYAML-6.0.1-cp312-cp312-win_amd64.whl (138 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.3 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Using cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: win32-setctime, urllib3, typing-extensions, tqdm, pyyaml, numpy, idna, dnspython, charset-normalizer, certifi, requests, loguru, pinecone-client\n",
      "Successfully installed certifi-2023.11.17 charset-normalizer-3.3.2 dnspython-2.4.2 idna-3.6 loguru-0.7.2 numpy-1.26.3 pinecone-client-2.2.4 pyyaml-6.0.1 requests-2.31.0 tqdm-4.66.1 typing-extensions-4.9.0 urllib3-2.1.0 win32-setctime-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pinecone-client\n",
    "! pip install faunadb\n",
    "! pip install ndg-httpsclient\n",
    "! pip install pyopenssl\n",
    "! pip install pyasn1\n",
    "! pip install -U sentence-transformers\n",
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrMFAV259gNf"
   },
   "source": [
    "\n",
    "<h1>Extract Data from .csv</h1>\n",
    "*   AB = Column that corresponds to the text of the abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKs6pKMBBwWK"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from itertools import islice\n",
    "import uuid\n",
    "\n",
    "# Load data, store abstract text\n",
    "batch_input = []\n",
    "with open('data/INLPT_class/articles.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        batch_input.append(row[\"AB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUv3RroBDykt",
    "outputId": "1aee9106-f709-4c2a-ca22-c2950586a140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57560\n"
     ]
    }
   ],
   "source": [
    "print(len(batch_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpNR2_Rh-W3M"
   },
   "source": [
    "<h3>PubMedBert is a on pubmed data finetuned BERT sentence embedding model. We embedd per Abstract</h3> \n",
    "*   https://huggingface.co/pritamdeka/S-PubMedBert-MS-MARCO\n",
    "\n",
    "<h3>E5-large-V2 a general-purpose embedding model for any tasks requiring a single-vector representation of texts such as retrieval, clustering, and classification   </h3>\n",
    "*   https://huggingface.co/intfloat/e5-large-v22\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fn_vZZmE-Fi7",
    "outputId": "e1a0897d-8f93-4112-add6-00f0f549a10b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      "  (2): Normalize()\n",
      ")\n",
      "BertTokenizerFast(name_or_path='intfloat/e5-large-v2', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "\n",
    "#embed data\n",
    "# model = SentenceTransformer('pritamdeka/S-PubMedBert-MS-MARCO')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('pritamdeka/S-PubMedBert-MS-MARCO')\n",
    "# max_token_size = 350\n",
    "# print(model)\n",
    "# print(tokenizer)\n",
    "\n",
    "model = SentenceTransformer('intfloat/e5-large-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-large-v2')\n",
    "max_token_size = 512\n",
    "print(model)\n",
    "print(tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Chunk data</h3>\n",
    "\n",
    "- Divide each abstract into chunks such that each chunk corresponds to max 512 tokens\n",
    "- Create overlaps between chunks\n",
    "- Add local context as metadata to each chunke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFWP7ixvhE6I"
   },
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "\n",
    "def get_front_context(s, m,overlap):\n",
    "  offset = len(overlap.split())\n",
    "  words = s.split()[:-offset]\n",
    "  output = []\n",
    "  count = 0\n",
    "  for word in reversed(words):\n",
    "    if(count > m):\n",
    "      break;\n",
    "    output.insert(0, word)\n",
    "    count += 1\n",
    "  return \" \".join(output)\n",
    "\n",
    "def get_back_context(s, m,overlap):\n",
    "  offset = len(overlap.split())\n",
    "  words = s.split()[offset:]\n",
    "  output = []\n",
    "  count = 0\n",
    "  for word in words:\n",
    "    if(count > m):\n",
    "      break;\n",
    "    output.append(word)\n",
    "    count += 1\n",
    "  return \" \".join(output)\n",
    "\n",
    "def combine_strings(string_1, string_2, n):\n",
    "    words_1 = string_1.split()\n",
    "    words_2 = string_2.split()\n",
    "    front = []\n",
    "    back = []\n",
    "    count = 0\n",
    "\n",
    "    for word in reversed(words_1):\n",
    "        token = tokenizer.convert_ids_to_tokens( tokenizer( word,add_special_tokens=False)[\"input_ids\"])\n",
    "        count += len(token)\n",
    "        if(count > n):\n",
    "            count = 0\n",
    "            break;\n",
    "        front.insert(0, word)\n",
    "\n",
    "    for word in words_2:\n",
    "        token = tokenizer.convert_ids_to_tokens( tokenizer( word,add_special_tokens=False)[\"input_ids\"])\n",
    "        count += len(token)\n",
    "        if(count > n):\n",
    "            count = 0\n",
    "            break;\n",
    "        back.append(word)\n",
    "\n",
    "    front = \" \".join(front)\n",
    "    back = \" \".join(back)\n",
    "    combined_string = front + \" \" + back\n",
    "    return (combined_string, front, back)\n",
    "\n",
    "def refine_sentences_fixed(s, sentences):\n",
    "    all_sentences = []\n",
    "    count = 0\n",
    "    words = sentences.split()\n",
    "    for word in words:\n",
    "        if(count % s == 0):\n",
    "            all_sentences.append([])\n",
    "            count = 0\n",
    "        token = tokenizer.convert_ids_to_tokens( tokenizer(word,add_special_tokens=False)[\"input_ids\"])\n",
    "        if(count + len(token) > s):\n",
    "            all_sentences.append([])\n",
    "            count = 0\n",
    "        count += len(token)\n",
    "        if not all_sentences[len(all_sentences)-1]:\n",
    "            all_sentences[len(all_sentences)-1].append(word)\n",
    "        else:\n",
    "            all_sentences[len(all_sentences)-1][0] +=  \" \" + word\n",
    "\n",
    "    return [item for sublist in all_sentences for item in sublist]\n",
    "\n",
    "def chop_text_by_words(text, n):\n",
    "    m = int(n*0.2)\n",
    "    token_size = max_token_size\n",
    "    dataForm = []\n",
    "    #chop text by tokens\n",
    "    text_chopped_by_words = refine_sentences_fixed(token_size, text)\n",
    "    #make list of tuples for medata and add overlaps\n",
    "    for i, chunk in enumerate(text_chopped_by_words):\n",
    "      if(len(text_chopped_by_words) == 1):\n",
    "        dataForm.append([\"query: \" + chunk, {\"front_context\": \"\"}, {\"back_context\":\"\"},str(uuid.uuid4()), text])\n",
    "        break;\n",
    "      if i == 0:\n",
    "          dataForm.append([\"query: \" + chunk, {\"front_context\": \"\"} , {\"back_context\": \" \".join(text_chopped_by_words[i+1].split()[:m])},str(uuid.uuid4()), text])\n",
    "          overlap = combine_strings(text_chopped_by_words[i],text_chopped_by_words[i+1], token_size/2)\n",
    "          dataForm.append([\"query: \" + overlap[0],{\"front_context\": get_front_context(str(text_chopped_by_words[i]),m,overlap[1])},{\"back_context\":get_back_context(text_chopped_by_words[i+1],m,overlap[2])},str(uuid.uuid4()), text])\n",
    "\n",
    "      elif i == len(text_chopped_by_words)-1:\n",
    "          dataForm.append([\"query: \" + chunk, {\"front_context\": \" \".join(text_chopped_by_words[i-1].split()[-(m):])}, {\"back_context\":\"\"},str(uuid.uuid4()), text])\n",
    "\n",
    "      else:\n",
    "          dataForm.append([\"query: \" + chunk, {\"front_context\": \" \".join(text_chopped_by_words[i-1].split()[-(m):])}, {\"back_context\": \" \".join(text_chopped_by_words[i+1].split()[:(m)])},str(uuid.uuid4()), text ])\n",
    "          overlap = combine_strings(text_chopped_by_words[i],text_chopped_by_words[i+1], token_size/2)\n",
    "          dataForm.append([\"query: \" + overlap[0],  {\"front_context\": get_front_context(str(text_chopped_by_words[i]),m,overlap[1])},{\"back_context\": get_back_context(text_chopped_by_words[i+1],m,overlap[2])},str(uuid.uuid4()), text])\n",
    "\n",
    "    return dataForm\n",
    "\n",
    "def remove_unicode_escape(s):\n",
    "    return re.sub(r'\\\\u....', '', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuyc83XdiQxj",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16c6498ead84f0aa370e7967b3cf8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "chunks = []\n",
    "for abstract in tqdm(batch_input):\n",
    "  chunks.append(chop_text_by_words(abstract, max_token_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Embedd data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01svN0PEVTMc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c55b8d47e5842789d5077610bd19340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embedding_list = []\n",
    "\n",
    "#This approach creates an embedding for every single chunk of an abstract (or one embedding for abstract if abstract didnt got chunked)\n",
    "all_abstract_chunks = [inner_list[0] for middle_list in chunks for inner_list in middle_list]\n",
    "multi_list = [embedding_list.append(model.encode(chunk)) for chunk in tqdm(all_abstract_chunks)]\n",
    "\n",
    "#This way of embedding results in one embedding per abstract <-> chunked abstracts will be merged together by mean-pooling, this makes no use out of the local context\n",
    "# for batch in tqdm(chunks):\n",
    "#   if(len(batch) == 1):\n",
    "#       embedding_list.append(model.encode(batch[0][0]))\n",
    "#   elif len(batch) > 1:\n",
    "#       flattened_list = [level_2 for level_1 in batch for level_2 in level_1[0:1] if level_1]\n",
    "#       multi_list = [model.encode(chunk) for chunk in flattened_list]\n",
    "#       embedding_list.append(np.mean(multi_list, axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   batch_input: List of abstracts\n",
    "-   chunks: List of lists of lists of chunked abstracts + local context for metadata +id + text of whole abstract\n",
    "-   embedding_list: list of embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_MWkqLF_Cbb"
   },
   "source": [
    "Create a vector that holds the data that is going to be uploaded to Pinecone Vector DB. To Pinecone we upload the embedding together with an id that maps the embedding to its original text in the DB (FaunaDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare data, initialize pinecone manager and upload</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "0g5muWkFAw4r",
    "outputId": "1be09a1c-d0b6-4e8c-c1c9-d95f4232f8a2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e1d19c14bf40b89a81c53763943e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "pinecone_vectors = []\n",
    "count = 0\n",
    "for batch in tqdm(chunks):\n",
    "    for data in batch:\n",
    "        pinecone_vectors.append((data[3], embedding_list[count].tolist()))\n",
    "        count += 1\n",
    "        \n",
    "#createvec = [{pinecone_vectors.append((data[3], embedding_list[count])),}  for batch in tqdm(chunks) for data in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOS8BZSwAk8T",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "#Init pinecone index\n",
    "pinecone.init(api_key=\"4d2c2cd0-cf55-43c5-afb1-11001dc68709\", environment=\"gcp-starter\")\n",
    "index = pinecone.Index(\"inlp-med-ws2324\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRUXD4AzqOy9"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "\n",
    "#Split data into m n-sized lists, used for bulk upload\n",
    "def bulk_upload(iterable, n):\n",
    "  bulk = [iterable[x:x+n] for x in range(0, len(iterable), n)]\n",
    "  return bulk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "rlIADzUeFjMx",
    "outputId": "b1c51a0c-589a-4dab-b412-5eb15993f4dc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dc0c8f2f414cac99528788b16255c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#upsert data to pinecone\n",
    "for ids_vectors_chunk in tqdm(bulk_upload(pinecone_vectors,500)):\n",
    "  index.upsert(vectors=ids_vectors_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNRn93foCBzO"
   },
   "source": [
    "<h3>Prepare Data, initialize FaunaDB client and upload</h3>\n",
    "\n",
    "*   https://v4.dashboard.fauna.com/db/eu/medicalData\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHGE7Qhah-w3"
   },
   "outputs": [],
   "source": [
    "#Initialize FaunaDB\n",
    "from faunadb import query as q\n",
    "from faunadb.objects import Ref\n",
    "from faunadb.client import FaunaClient\n",
    "\n",
    "client = FaunaClient(\n",
    "  secret=\"fnAFW8NnOqAAzXyJUw9gkBUoCOopcrX3c8zdIJy0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pT_UhYM5CJi-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67080\n"
     ]
    }
   ],
   "source": [
    "chunk_test = chunks\n",
    "upload = []\n",
    "for chunk in chunk_test:\n",
    "    for data in chunk:\n",
    "        upload.append(data)\n",
    "            \n",
    "print(len(upload))\n",
    "chunkeddata = bulk_upload(upload, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yjIPoVzpLYR"
   },
   "outputs": [],
   "source": [
    "#Upload data into FaunaDB\n",
    "def upload_data_to_fauna(data):\n",
    "        for row in data:\n",
    "            client.query(q.create(q.collection(\"metadata\"),{\"data\": {\"chunk\": row[0], \"front_context\": row[1],\"back_context\": row[2],\"id\": row[3],\"abstract\": row[4]}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nsJYeVI5A9w"
   },
   "outputs": [],
   "source": [
    "for i in range(len(chunkeddata)):\n",
    "  upload_data_to_fauna(chunkeddata[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwyyWG-qOtRL"
   },
   "source": [
    "How to query from Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uKpqgFe_Toxf",
    "outputId": "42db386b-13aa-4b75-98a9-cc97872adb72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '65639466-3a21-4e2d-8c91-6fc106523e02',\n",
       "              'score': 0.850698709,\n",
       "              'values': []},\n",
       "             {'id': 'ef02e706-a21f-44c7-94f4-d79f1969b22f',\n",
       "              'score': 0.844490886,\n",
       "              'values': []},\n",
       "             {'id': '7e9e6077-1f25-4b27-abb4-b477a17144b2',\n",
       "              'score': 0.835636497,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_document(query):\n",
    "  embeded_vector = model.encode(query).tolist()\n",
    "\n",
    "  query_response = index.query(\n",
    "      embeded_vector,\n",
    "      top_k=3,\n",
    "      )\n",
    "  return query_response\n",
    "\n",
    "return_document(\"CASK disorder phenotype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npoqkqNnPCu1"
   },
   "source": [
    "How to Query from FaunaDB, first create index then query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2j-PrNpmA1T3",
    "outputId": "0efa5ab0-00f4-45db-ced2-a9953f2d530d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [['query: CLINICAL CHARACTERISTICS: CASK disorders include a spectrum of phenotypes in both females and males. Two main types of clinical presentation are seen: Microcephalywith pontine and cerebellar hypoplasia (MICPCH), generally associated withpathogenic loss-of-function variants in CASK. X-linked intellectual disability(XLID) with or without nystagmus, generally associated with hypomorphic CASKpathogenic variants. MICPCH is typically seen in females with moderate-to-severeintellectual disability, progressive microcephaly with or without ophthalmologicanomalies, and sensorineural hearing loss. Most are able to sit independently;20%-25% attain the ability to walk; language is nearly absent in most. Neurologicfeatures may include axial hypotonia, hypertonia/spasticity of the extremities,and dystonia or other movement disorders. Nearly 40% have seizures by age tenyears. Behaviors may include sleep disturbances, hand stereotypies, and selfbiting. MICPCH in males may occur with or without severe epileptic encephalopathyin addition to severe-to-profound developmental delay. When seizures are presentthey occur early and may be intractable. In individuals and families with milder(i.e., hypomorphic) pathogenic variants, the clinical phenotype is usually thatof XLID with or without nystagmus and additional clinical features. Males havemild-to-severe intellectual disability, with or without nystagmus and otherocular features. Females typically have normal intelligence with some displayingmild-to-severe intellectual disability with or without ocular features.DIAGNOSIS/TESTING: The diagnosis of a CASK disorder is established in a femalewho is heterozygous for a CASK pathogenic variant and in a male who is hemizygousfor a CASK pathogenic variant on molecular genetic testing. Rarely, affectedmales have a mosaic pathogenic variant. MANAGEMENT: Treatment of manifestations:Treatment is symptomatic and includes standard management of developmental delayand intellectual disability issues; medication for seizures; nutritional support;use of physiotherapy; and treatment of abnormal vision or hearing loss. GENETICCOUNSELING: CASK disorders are inherited in an X-linked manner. Risk to thefamily members of a proband with a', None, None, 'CLINICAL CHARACTERISTICS: CASK disorders include a spectrum of phenotypes in both females and males. Two main types of clinical presentation are seen: Microcephalywith pontine and cerebellar hypoplasia (MICPCH), generally associated withpathogenic loss-of-function variants in CASK. X-linked intellectual disability(XLID) with or without nystagmus, generally associated with hypomorphic CASKpathogenic variants. MICPCH is typically seen in females with moderate-to-severeintellectual disability, progressive microcephaly with or without ophthalmologicanomalies, and sensorineural hearing loss. Most are able to sit independently;20%-25% attain the ability to walk; language is nearly absent in most. Neurologicfeatures may include axial hypotonia, hypertonia/spasticity of the extremities,and dystonia or other movement disorders. Nearly 40% have seizures by age tenyears. Behaviors may include sleep disturbances, hand stereotypies, and selfbiting. MICPCH in males may occur with or without severe epileptic encephalopathyin addition to severe-to-profound developmental delay. When seizures are presentthey occur early and may be intractable. In individuals and families with milder(i.e., hypomorphic) pathogenic variants, the clinical phenotype is usually thatof XLID with or without nystagmus and additional clinical features. Males havemild-to-severe intellectual disability, with or without nystagmus and otherocular features. Females typically have normal intelligence with some displayingmild-to-severe intellectual disability with or without ocular features.DIAGNOSIS/TESTING: The diagnosis of a CASK disorder is established in a femalewho is heterozygous for a CASK pathogenic variant and in a male who is hemizygousfor a CASK pathogenic variant on molecular genetic testing. Rarely, affectedmales have a mosaic pathogenic variant. MANAGEMENT: Treatment of manifestations:Treatment is symptomatic and includes standard management of developmental delayand intellectual disability issues; medication for seizures; nutritional support;use of physiotherapy; and treatment of abnormal vision or hearing loss. GENETICCOUNSELING: CASK disorders are inherited in an X-linked manner. Risk to thefamily members of a proband with a CASK disorder depends on the phenotype (i.e.,MICPCH or XLID +/- nystagmus) in the proband. MICPCH. Most affected females andmales represent simplex cases (i.e., the only affected family member) and havethe disorder as the result of a de novo CASK pathogenic variant. Becauseheterozygous females manifest the phenotype, an asymptomatic mother is unlikelyto be heterozygous for the CASK pathogenic variant. If a proband represents asimplex case, the recurrence risk to sibs appears to be low but greater than thatof the general population because of the possibility of parental germlinemosaicism. XLID +/- nystagmus. The father of a male with a CASK disorder will nothave the disorder nor will he be hemizygous for the CASK pathogenic variant. If amale is the only affected family member, the mother may be a heterozygote or theaffected male may have a de novo pathogenic variant. In a family with more thanone affected individual, the mother of an affected male is an obligateheterozygote. If the mother of the proband has a CASK pathogenic variant, thechance of transmitting it in each pregnancy is 50%: males who inherit thepathogenic variant will be affected; females who inherit the pathogenic variantwill typically be asymptomatic but may have a range of manifestations. If theCASK pathogenic variant cannot be detected in maternal leukocyte DNA, the risk tosibs is greater than that of the general population because of the possibility ofparental germline mosaicism. Once the CASK pathogenic variant has been identifiedin an affected family member, prenatal testing for a pregnancy at increased riskand preimplantation genetic testing for a CASK disorder are possible.', '65639466-3a21-4e2d-8c91-6fc106523e02']]}\n"
     ]
    }
   ],
   "source": [
    "result = client.query(\n",
    "  q.paginate(q.match(q.index(\"metadata\"), \"65639466-3a21-4e2d-8c91-6fc106523e02\"))\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2FAl_RoPF6C"
   },
   "source": [
    "ToDo: Implement Pinecone and FaunaDB API into backend\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

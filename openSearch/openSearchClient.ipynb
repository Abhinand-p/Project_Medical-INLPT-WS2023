{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize connection to opensearch\n",
    "host = 'localhost'\n",
    "port = 9200\n",
    "auth = ('admin', 'admin') \n",
    "\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = False,\n",
    "    timeout=100\n",
    ")\n",
    "#check status\n",
    "print(client.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create VectorDB index:\n",
    "\n",
    "index_name = \"med_data\"\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "    \"index\": {\n",
    "      \"knn\": True,\n",
    "      \"knn.algo_param.ef_search\": 100\n",
    "    }\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "        \"vector\": {\n",
    "          \"type\": \"knn_vector\",\n",
    "          \"dimension\": 1024,     #Thats the output dimension of the e5 model\n",
    "          \"method\": {\n",
    "            \"name\": \"hnsw\",\n",
    "            \"space_type\": \"l2\",\n",
    "            \"engine\": \"nmslib\",\n",
    "            \"parameters\": {\n",
    "              \"ef_construction\": 128,\n",
    "              \"m\": 24\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "response = client.indices.create(index_name, body = index_body)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Load data that was created by embedding\\strategy_3\n",
    "file_path = '../embedding/strategy_3/data.txt'\n",
    "\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    loaded_list = pickle.load(file)\n",
    "\n",
    "\n",
    "print(len(loaded_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_list(input_list, n):\n",
    "    chunk_size = len(input_list) // n\n",
    "    remainder = len(input_list) % n\n",
    "\n",
    "    start = 0\n",
    "    result = []\n",
    "\n",
    "    for i in range(n):\n",
    "        end = start + chunk_size + (1 if i < remainder else 0)\n",
    "        result.append(input_list[start:end])\n",
    "        start = end\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = divide_list(loaded_list, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result[0]))\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "data_for_bulk_insert = []\n",
    "\n",
    "for batch in tqdm(result):\n",
    "    for chunk in batch:\n",
    "        data_for_bulk_insert.append({\"index\": {\"_index\": index_name, \"_id\": str(uuid.uuid4())}})\n",
    "        data_for_bulk_insert.append({\"vector\" : chunk[0], \"text\" : chunk[1], \"PMID\" : chunk[2], \"TI\" : chunk[3], \"PB\": chunk[4], \"FAU\": chunk[5], \"FED\": chunk[6], \"DP\": chunk[7], \"OTO\": chunk[8], \"ISBN\" : chunk[9] })\n",
    "    response = client.bulk(data_for_bulk_insert)\n",
    "    data_for_bulk_insert = []"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
